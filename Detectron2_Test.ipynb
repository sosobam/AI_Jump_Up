{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (1) 종속 패키지 설치"
      ],
      "metadata": {
        "id": "nM7Ls7VVWC-A"
      },
      "id": "nM7Ls7VVWC-A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689575e8",
      "metadata": {
        "id": "689575e8"
      },
      "outputs": [],
      "source": [
        "# 종속 패키지(dependencies) 설치(pytorch, detectron2)\n",
        "!pip install -U torch torchvision cython\n",
        "!pip install -U 'git+https://github.com/facebookresearch/fvcore.git' 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo\n",
        "\n",
        "# 인스톨이 완료되면 Colab Runtime을 다시 시작해주세요. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) 유틸 Import"
      ],
      "metadata": {
        "id": "rLm9rBiMWHhb"
      },
      "id": "rLm9rBiMWHhb"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1134cdea",
      "metadata": {
        "id": "1134cdea"
      },
      "outputs": [],
      "source": [
        "# 기본 설정\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "import itertools\n",
        "\n",
        "# detectron2 logger 설정\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# 자주 사용하는 라이브러리 임폴트\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 자주 사용하는 detectron2 유틸 임폴트 \n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) github에서 TRAIN, VAL data들 가져오기"
      ],
      "metadata": {
        "id": "ao0bfHsDWLzR"
      },
      "id": "ao0bfHsDWLzR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7d124e",
      "metadata": {
        "id": "fa7d124e"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sosobam/AI_Jump_up.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) detectron2에서 데이터셋 정보를 로드하는 형식에 맞춰 함수를 작성"
      ],
      "metadata": {
        "id": "TC213Cv8WVfF"
      },
      "id": "TC213Cv8WVfF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "48db5cf3",
      "metadata": {
        "id": "48db5cf3"
      },
      "outputs": [],
      "source": [
        "# 이미지 경로에서 Data set 뽑는 함수\n",
        "def get_PTN_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"annotations.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    # 최종 결과물\n",
        "    dataset_dicts = []\n",
        "    \n",
        "    idx = 0\n",
        "    # 이미지들을 annotation한 json에서 이미지별로 하나씩 데이터 뽑아서 record에 저장(key : 이미지file.jpg, val : seg데이터)\n",
        "    for key, val in imgs_anns.items():\n",
        "        record = {} # 각 이미지별 정보 담을 dataset 포맷\n",
        "        \n",
        "        filename = os.path.join(img_dir, key) # 이미지file 경로\n",
        "        height, width = cv2.imread(filename).shape[:2] # 이미지file 경로로 cv2로 이미지 열어서 height, width 추출\n",
        "        \n",
        "        # 이미지 기본정보\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = val[\"instances\"]\n",
        "        objs = []\n",
        "\n",
        "        # 이미지 기본정보 중 annotation_class별로 point들(x,y,x,y,x,y,...x,y순서) 뽑아서 obj에 담고 objs에 class별로 누적 후 record[\"annotations\"]에 최종 저장\n",
        "        for anno in annos:\n",
        "            points = anno[\"points\"]\n",
        "            px = []\n",
        "            py = []\n",
        "\n",
        "            # point들(x,y,x,y,x,y,...x,y순서) 뽑아서 px, py로 각각 list 생성\n",
        "            for i in range(0,int(len(points)/2)):\n",
        "              px = px + [points[i*2]] # 짝수\n",
        "              py = px + [points[i*2+1]] # 홀수\n",
        "\n",
        "            # px, py list를 poly에 (x,y)형태로 묶어서 다시 list화\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = list(itertools.chain.from_iterable(poly))\n",
        "\n",
        "            # obj dict에 (x,y)list를 토대로 Box만들고 list 등록\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": 0,\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj) # obj를 objs에 누적\n",
        "        record[\"annotations\"] = objs # objs를 record[\"annotations\"]에 등록\n",
        "        dataset_dicts.append(record) # record를 dataset에 누적\n",
        "    return dataset_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (5) train, val 이미지들을 metadata set에 등록"
      ],
      "metadata": {
        "id": "fbTbAph9Wl1s"
      },
      "id": "fbTbAph9Wl1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8f88c3",
      "metadata": {
        "id": "6f8f88c3"
      },
      "outputs": [],
      "source": [
        "for d in [\"TRAIN\", \"VAL\"]:\n",
        "    DatasetCatalog.register(\"PTN_\" + d, lambda d=d: get_PTN_dicts(\"AI_Jump_up/\"+d))\n",
        "    MetadataCatalog.get(\"PTN_\" + d).set(thing_classes=[\"PTN\"])\n",
        "PTN_metadata = MetadataCatalog.get(\"PTN_TRAIN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (6) 데이터가 제대로 로드되었는지 확인"
      ],
      "metadata": {
        "id": "uubed2fVWnam"
      },
      "id": "uubed2fVWnam"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3b7ba6",
      "metadata": {
        "id": "8d3b7ba6"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_PTN_dicts(\"AI_Jump_up/TRAIN\")\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=PTN_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (7) 학습하기"
      ],
      "metadata": {
        "id": "9NR7dFlJXD7K"
      },
      "id": "9NR7dFlJXD7K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7.1) Instance Segmentation 학습"
      ],
      "metadata": {
        "id": "FaREBgLhYlh5"
      },
      "id": "FaREBgLhYlh5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "자 이제 학습을 진행할 단계입니다. COCO 데이터셋으로 학습된 R50-FPN Mask R-CNN 모델을 불러와서 풍선 데이터셋으로 fine-tune해 봅시다.\n",
        "Colab의 K80 GPU를 기준으로, 300 iterations 학습시키는데 대략 6분정도의 시간이 소요됩니다(P100 GPU의 경우 2분 가량 소요됩니다)."
      ],
      "metadata": {
        "id": "oBb_B8hjW-2H"
      },
      "id": "oBb_B8hjW-2H"
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"PTN_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 100    # 300 iterations 정도면 충분합니다. 더 오랜 시간도 시도해보세요.\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # 풍선 데이터셋과 같이 작은 데이터셋에서는 이정도면 적당합니다.\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # 클래스는 \"풍선\" 클래스 하나 뿐입니다.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "zDAPvrT-V4b0"
      },
      "id": "zDAPvrT-V4b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7.2) 학습 커브 확인"
      ],
      "metadata": {
        "id": "b6HnZgehXpUn"
      },
      "id": "b6HnZgehXpUn"
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard를 사용해서 학습 커브를 살펴봅니다.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "0YBOidu3XsoF"
      },
      "id": "0YBOidu3XsoF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7.3) 학습한 모델 실행 및 평가하기\n",
        "자 이제 풍선 데이터셋의 검증(validation) 데이터셋으로 테스트를 해볼 차례입니다. \n",
        "\n",
        "우선, 방금 전 학습한 모델을 불러와서 `predictor`를 생성합니다."
      ],
      "metadata": {
        "id": "9Jf5p-ShX157"
      },
      "id": "9Jf5p-ShX157"
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"VAL\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "qwuI2qi7brYd"
      },
      "id": "qwuI2qi7brYd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7.4) 샘플 검증"
      ],
      "metadata": {
        "id": "ewkfj5a6bsiD"
      },
      "id": "ewkfj5a6bsiD"
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_PTN_dicts(\"VAL\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=balloon_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "SFjUmJ2zbyh7"
      },
      "id": "SFjUmJ2zbyh7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}